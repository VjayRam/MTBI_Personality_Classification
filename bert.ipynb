{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (4.23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: requests in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (0.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.9.1-py3-none-any.whl (199 kB)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Downloading scikit_learn-1.1.2-cp39-cp39-win_amd64.whl (7.4 MB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vijay ram\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "Successfully installed imbalanced-learn-0.9.1 imblearn-0.0 scikit-learn-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertModel\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import TFRobertaModel\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y, y_pred, title):\n",
    "    fig, ax =plt.subplots(figsize=(13,13))\n",
    "    labels=['anger', 'boredom', 'empty','enthusiasm','fun','hapiness','hate','love','neutral','relief','sadness','surprise','worry']\n",
    "    ax=sns.heatmap(confusion_matrix(y, y_pred), annot=True, cmap=\"Blues\", fmt='g', cbar=False, annot_kws={\"size\":25})\n",
    "    plt.title(title, fontsize=20)\n",
    "    ax.xaxis.set_ticklabels(labels, fontsize=17) \n",
    "    ax.yaxis.set_ticklabels(labels, fontsize=17)\n",
    "    ax.set_ylabel('Test', fontsize=20)\n",
    "    ax.set_xlabel('Predicted', fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type     0\n",
       "posts    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    1832\n",
       "INFJ    1470\n",
       "INTP    1304\n",
       "INTJ    1091\n",
       "ENTP     685\n",
       "ENFP     675\n",
       "ISTP     337\n",
       "ISFP     271\n",
       "ENTJ     231\n",
       "ISTJ     205\n",
       "ENFJ     190\n",
       "ISFJ     166\n",
       "ESTP      89\n",
       "ESFP      48\n",
       "ESFJ      42\n",
       "ESTJ      39\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    'I'm finding the lack of me in these posts ver...\n",
       "2    'Good one  _____   https://www.youtube.com/wat...\n",
       "3    'Dear INTP,   I enjoyed our conversation the o...\n",
       "4    'You're fired.|||That's another silly misconce...\n",
       "5    '18/37 @.@|||Science  is not perfect. No scien...\n",
       "6    'No, I can't draw on my own nails (haha). Thos...\n",
       "7    'I tend to build up a collection of things on ...\n",
       "8    I'm not sure, that's a good question. The dist...\n",
       "9    'https://www.youtube.com/watch?v=w8-egj0y8Qs||...\n",
       "Name: posts, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"posts\"][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_posts\"] = df[\"posts\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_list = stopwords.words(\"english\")\n",
    "df['new_posts'] = df['new_posts'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>new_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsxhcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>'i'm finding lack posts alarming.|||sex boring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>'good one _____ https://www.youtube.com/watch?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>'dear intp, enjoyed conversation day. esoteric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>'you're fired.|||that's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edhb_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>'so...if thread already exists someplace else ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>'so many questions things. would take purple p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>'i conflicted right comes wanting children. ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>'it long since personalitycafe - although seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "...    ...                                                ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...   \n",
       "8672  INTP  'So many questions when i do these things.  I ...   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...   \n",
       "8674  INFP  'It has been too long since I have been on per...   \n",
       "\n",
       "                                              new_posts  \n",
       "0     'http://www.youtube.com/watch?v=qsxhcwe3krw|||...  \n",
       "1     'i'm finding lack posts alarming.|||sex boring...  \n",
       "2     'good one _____ https://www.youtube.com/watch?...  \n",
       "3     'dear intp, enjoyed conversation day. esoteric...  \n",
       "4     'you're fired.|||that's another silly misconce...  \n",
       "...                                                 ...  \n",
       "8670  'https://www.youtube.com/watch?v=t8edhb_h908||...  \n",
       "8671  'so...if thread already exists someplace else ...  \n",
       "8672  'so many questions things. would take purple p...  \n",
       "8673  'i conflicted right comes wanting children. ho...  \n",
       "8674  'it long since personalitycafe - although seem...  \n",
       "\n",
       "[8675 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_len = []\n",
    "for text in df.new_posts:\n",
    "    text_l = len(text.split())\n",
    "    text_len.append(text_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_len'] = text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df['text_len'] < 1)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = sns.countplot(x='cont_len', data=df[df['cont_len']<10], palette='mako')\n",
    "plt.title('Training tweets with less than 10 words')\n",
    "plt.yticks([])\n",
    "\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e49839846391b100bcb2f01682fcebdf72015f4f3b1f99a783c0d5b358a996b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
